{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Temporal Fusion Transformer predictor using PyTorch-Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-level requirements: pytorch-forecasting, ipykernel, jupyter, tensorboard, plotly, citylearn==1.7\n",
    "# install numba for improved speed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following along with training example provided in docs - https://github.com/jdb78/pytorch-forecasting & https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/stallion.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for training\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "# import dataset, network to train and metric to optimize\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dataset from CSV\n",
    "csv_fname = 'UCam_Building_5'\n",
    "dataset_dir = os.path.join('data','example') # dataset directory\n",
    "train_data = pd.read_csv(os.path.join(dataset_dir,'test',f'{csv_fname}.csv'),usecols=['Month','Hour','Day Type','Daylight Savings Status','Equipment Electric Power [kWh]'])\n",
    "train_data['Outdoor Drybulb Temperature [C]'] = pd.read_csv(os.path.join(dataset_dir,'test','weather.csv'),usecols=['Outdoor Drybulb Temperature [C]'])\n",
    "val_data = pd.read_csv(os.path.join(dataset_dir,'validate',f'{csv_fname}.csv'),usecols=['Month','Hour','Day Type','Daylight Savings Status','Equipment Electric Power [kWh]'])\n",
    "val_data['Outdoor Drybulb Temperature [C]'] = pd.read_csv(os.path.join(dataset_dir,'validate','weather.csv'),usecols=['Outdoor Drybulb Temperature [C]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_df(df):\n",
    "    df = df.rename_axis('time_idx').reset_index() # create column of indices to pass as time_idx to TimeSeriesDataSet - we have no missing values\n",
    "    df['ts_id'] = f'b{5}' # create column with ID of timeseries (use f'b{UCam building ID}')\n",
    "    for col in ['Month','Hour','Day Type','Daylight Savings Status']:\n",
    "        df[col] = df[col].astype(str) # convert to strs to use as categoric covariates\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = [reformat_df(df) for df in [train_data, val_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training dataset\n",
    "max_encoder_length = 48 # max number of previous instances to use for prediction\n",
    "max_prediction_length = 24 # max forecasting horizon\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx= 'time_idx',  # column name of time of observation\n",
    "    target= 'Equipment Electric Power [kWh]',  # column name of target to predict\n",
    "    group_ids=['ts_id'],  # column name(s) for timeseries IDs\n",
    "    max_encoder_length=max_encoder_length,  # how much history to use\n",
    "    max_prediction_length=max_prediction_length,  # how far to predict into future\n",
    "    # covariates static for a timeseries ID - ignore for the moment\n",
    "    #static_categoricals=[ ... ],\n",
    "    #static_reals=[ ... ],\n",
    "    # covariates known and unknown in the future to inform prediction\n",
    "    time_varying_known_categoricals=['Month','Hour','Day Type','Daylight Savings Status'],\n",
    "    #time_varying_known_reals=[ ... ],\n",
    "    #time_varying_unknown_categoricals=[ ... ],\n",
    "    time_varying_unknown_reals=['Equipment Electric Power [kWh]','Outdoor Drybulb Temperature [C]'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation dataset using the same normalization techniques as for the training dataset\n",
    "validation = TimeSeriesDataSet.from_dataset(training, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datasets to dataloaders for training\n",
    "batch_size = 128\n",
    "n_workers = 4\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=n_workers)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=n_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_trainer = pl.Trainer(\n",
    "    deterministic=True,\n",
    "    #gpus=0,\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=0.1, # clipping gradients is a hyperparameter and important to prevent divergance of the gradient for recurrent neural networks\n",
    "    logger=TensorBoardLogger(save_dir=os.path.join(\"lightning_logs\",\"TFT-test\",\"lr_tuning\"), name=f'{csv_fname}')\n",
    ")\n",
    "\n",
    "\n",
    "# define network to train - the architecture is mostly inferred from the dataset, so that only a few hyperparameters have to be set by the user\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    # dataset\n",
    "    training,\n",
    "    # architecture hyperparameters\n",
    "    hidden_size=48,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    # loss metric to optimize\n",
    "    loss=QuantileLoss(),\n",
    "    # set optimizer\n",
    "    optimizer='adam',\n",
    "    # optimizer parameters\n",
    "    learning_rate=0.03,\n",
    "    reduce_on_plateau_patience=5\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is going to be a hefty hparam optimisation\n",
    "# # create study\n",
    "# study = optimize_hyperparameters(\n",
    "#     train_dataloader,\n",
    "#     val_dataloader,\n",
    "#     model_path=\"optuna_test\",\n",
    "#     n_trials=200,\n",
    "#     max_epochs=50,\n",
    "#     gradient_clip_val_range=(0.01, 1.0),\n",
    "#     hidden_size_range=(8, 128),\n",
    "#     hidden_continuous_size_range=(8, 128),\n",
    "#     attention_head_size_range=(1, 4),\n",
    "#     learning_rate_range=(0.001, 0.1),\n",
    "#     dropout_range=(0.1, 0.3),\n",
    "#     trainer_kwargs=dict(limit_train_batches=30),\n",
    "#     reduce_on_plateau_patience=4,\n",
    "#     use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PyTorch Lighning Trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-6, patience=5, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
    "tb_logger = TensorBoardLogger(save_dir=os.path.join(\"lightning_logs\",\"TFT-test\"), name=f'{csv_fname}')\n",
    "trainer = pl.Trainer(\n",
    "    deterministic=True,\n",
    "    accelerator='cpu',\n",
    "    max_epochs=100,\n",
    "    #gpus=0,  # run on CPU, if on multiple GPUs, use accelerator=\"ddp\"\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=500,  # batches per epoch\n",
    "    callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n",
    "    logger=tb_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network to train - can I just load this?\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    # dataset\n",
    "    training,\n",
    "    # architecture hyperparameters\n",
    "    hidden_size=48,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    # loss metric to optimize\n",
    "    loss=QuantileLoss(),\n",
    "    # set optimizer\n",
    "    optimizer='adam',\n",
    "    # optimizer parameters\n",
    "    learning_rate=res.suggestion(),\n",
    "    reduce_on_plateau_patience=5\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on the data \n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    #ckpt_path='best' # use of re-training after load\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "# I can then save the best model path in the checkpointing directory\n",
    "\n",
    "# os.path.join('lightning_logs','TFT-test', 'UCam_Building_5','version_3','checkpoints','epoch=18-step=2584.ckpt')\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "tft.eval() # enable evaluation mode, disable randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = tft.predict(val_dataloader)\n",
    "print((actuals - predictions).abs().mean())\n",
    "print(val_data['Equipment Electric Power [kWh]'].abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(predictions[245]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions, x = tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "print(tft.loss.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tft.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_predictions.keys())\n",
    "print(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_predictions['prediction'].shape)\n",
    "print(x['decoder_target'].shape)\n",
    "print(x['encoder_target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, main_ax = plt.subplots()\n",
    "idx = 3000\n",
    "fig = tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True, ax=main_ax)\n",
    "axs = fig.get_axes()\n",
    "axs[0].set_ylabel('Electrical Load (kWh)')\n",
    "prediction_loss = float(axs[0].get_title().split(' ')[1])\n",
    "axs[0].set_title(f'Timestep: {idx}   Loss: {round(prediction_loss,4)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kWh_max = 300\n",
    "# start = 1000\n",
    "\n",
    "# fig, main_ax = plt.subplots()\n",
    "# alt_ax = main_ax.twinx()\n",
    "\n",
    "# def animate(i,offset=start):\n",
    "#     idx = i + offset\n",
    "\n",
    "#     main_ax.clear()\n",
    "#     alt_ax.clear()\n",
    "\n",
    "#     main_ax.set_ylim(0,kWh_max)\n",
    "#     alt_ax.set_ylim(0,np.max(np.array(raw_predictions['encoder_attention'])))\n",
    "#     main_ax.set_ylabel('Electrical Load (kWh)')\n",
    "\n",
    "#     # plot attention manually - taken from source code, https://pytorch-forecasting.readthedocs.io/en/stable/_modules/pytorch_forecasting/models/temporal_fusion_transformer.html#TemporalFusionTransformer.plot_prediction\n",
    "#     encoder_length = x[\"encoder_lengths\"][0]\n",
    "#     interpretation = tft.interpret_output(raw_predictions.iget(slice(idx, idx + 1)))\n",
    "#     alt_ax.plot([-1*i for i in reversed(range(1,encoder_length+1))],interpretation['attention'][0,-encoder_length:], c='k', alpha=0.2)\n",
    "\n",
    "#     tft.plot_prediction(x, raw_predictions, idx=idx, plot_attention=False, add_loss_to_title=True, ax=main_ax)\n",
    "\n",
    "#     prediction_loss = float(main_ax.get_title().split(' ')[1])\n",
    "#     main_ax.set_title(f'Timestep: {idx}' + ' '*4 + 'Loss: ' + f'{prediction_loss:.3f}'.rjust(6), loc='center')\n",
    "\n",
    "#     return *main_ax.get_lines(), *alt_ax.get_lines()\n",
    "\n",
    "# n_frames = 24*14\n",
    "# anim = animation.FuncAnimation(fig, animate, frames=n_frames, interval=200, blit=True)\n",
    "# writer = animation.writers['ffmpeg']()\n",
    "# anim.save('predict_anim.mp4', writer=writer, dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot as ply_plot\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "duration = 24*7*12\n",
    "idx_start = 0\n",
    "idx_end = idx_start+duration\n",
    "\n",
    "max_encoder_length = 48\n",
    "max_prediction_length = 24\n",
    "kWh_max = 300\n",
    "max_attention = 0.4\n",
    "transition_duration = 0\n",
    "frame_duration = 100\n",
    "\n",
    "prediction_losses = []\n",
    "\n",
    "# make figure\n",
    "fig_dict = {\n",
    "    \"data\": [],\n",
    "    \"layout\": {},\n",
    "    \"frames\": []\n",
    "}\n",
    "\n",
    "# fill in most of layout\n",
    "fig_dict[\"layout\"][\"xaxis\"] = {\"range\": [-1*(max_encoder_length+1), max_prediction_length+2], \"showgrid\":True}\n",
    "fig_dict[\"layout\"][\"hovermode\"] = \"closest\"\n",
    "fig_dict[\"layout\"][\"updatemenus\"] = [\n",
    "    {\n",
    "        \"buttons\": [\n",
    "            {\n",
    "                \"args\": [None, {\"frame\": {\"duration\": frame_duration, \"redraw\": False},\n",
    "                                \"fromcurrent\": True,\n",
    "                                \"transition\": {\"duration\": transition_duration, \"easing\": \"linear\"}\n",
    "                                }],\n",
    "                \"label\": \"Play\",\n",
    "                \"method\": \"animate\"\n",
    "            },\n",
    "            {\n",
    "                \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                  \"mode\": \"immediate\",\n",
    "                                  \"transition\": {\"duration\": 0}\n",
    "                                    }],\n",
    "                \"label\": \"Pause\",\n",
    "                \"method\": \"animate\"\n",
    "            }\n",
    "        ],\n",
    "        \"direction\": \"left\",\n",
    "        \"pad\": {\"r\": 10, \"t\": 87},\n",
    "        \"showactive\": False,\n",
    "        \"type\": \"buttons\",\n",
    "        \"x\": 0.1,\n",
    "        \"xanchor\": \"right\",\n",
    "        \"y\": 0,\n",
    "        \"yanchor\": \"top\"\n",
    "    }\n",
    "]\n",
    "\n",
    "sliders_dict = {\n",
    "    \"active\": 0,\n",
    "    \"yanchor\": \"top\",\n",
    "    \"xanchor\": \"left\",\n",
    "    \"currentvalue\": {\n",
    "        \"font\": {\"size\": 12},\n",
    "        \"prefix\": \"Timestep: \",\n",
    "        \"visible\": True,\n",
    "        \"xanchor\": \"right\"\n",
    "    },\n",
    "    \"transition\": {\"duration\": transition_duration, \"easing\": \"linear\"},\n",
    "    \"pad\": {\"b\": 10, \"t\": 50},\n",
    "    \"len\": 0.9,\n",
    "    \"x\": 0.1,\n",
    "    \"y\": 0,\n",
    "    \"steps\": []\n",
    "}\n",
    "\n",
    "# make frames\n",
    "for j,idx in tqdm(enumerate(range(idx_start,idx_end+1))):\n",
    "\n",
    "    frame = {\"data\": [], \"name\": str(idx)}\n",
    "\n",
    "    # get encoder length, compute attention\n",
    "    encoder_length = x[\"encoder_lengths\"][0]\n",
    "    interpretation = tft.interpret_output(raw_predictions.iget(slice(idx, idx + 1)))\n",
    "\n",
    "    # outrageously hacky way of computing prediction loss\n",
    "    fig, dummy_ax = plt.subplots()\n",
    "    tft.plot_prediction(x, raw_predictions, idx=idx, plot_attention=False, add_loss_to_title=True, ax=dummy_ax)\n",
    "    prediction_loss = float(dummy_ax.get_title().split(' ')[1])\n",
    "    plt.close(fig)\n",
    "    del fig, dummy_ax\n",
    "    prediction_losses.append(prediction_loss)\n",
    "\n",
    "    # construct plots for each frame\n",
    "    plot_data = [\n",
    "        go.Bar( # prediction loss bar chart\n",
    "            x=[max_prediction_length+1],\n",
    "            y=[prediction_loss],\n",
    "            width=1,\n",
    "            marker=dict(color=\"rgba(244, 50, 12, 1)\"),\n",
    "            name=\"Loss\",\n",
    "            yaxis='y2',\n",
    "        ),\n",
    "\n",
    "        go.Scatter( # p95 area fill\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,0],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.1)\", width=0),\n",
    "            name=\"p95\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,6],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.1)\", width=0),\n",
    "            name=\"p95\",\n",
    "            fill='tonexty'\n",
    "        ),\n",
    "        go.Scatter( # p80 area fill\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,1],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.2)\", width=0),\n",
    "            name=\"p80\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,5],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.2)\", width=0),\n",
    "            name=\"p80\",\n",
    "            fill='tonexty'\n",
    "        ),\n",
    "        go.Scatter( # p50 area fill\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,2],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.4)\", width=0),\n",
    "            name=\"p50\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,4],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(249, 115, 6, 0.4)\", width=0),\n",
    "            name=\"p50\",\n",
    "            fill='tonexty'\n",
    "        ),\n",
    "\n",
    "        go.Scatter( # encoder attention\n",
    "            x=[-1*i for i in reversed(range(1,encoder_length+1))],\n",
    "            y=interpretation['attention'][0,-encoder_length:],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(63, 155, 11, 0.5)\", width=2),\n",
    "            yaxis='y3',\n",
    "            name=\"Attention\"\n",
    "        ),\n",
    "        go.Scatter( # decoder target\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=x['decoder_target'][idx],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(1, 21, 62, 1)\", width=2),\n",
    "            legendgroup=\"target\",\n",
    "            name=\"Target\"\n",
    "        ),\n",
    "        go.Scatter( # encoder target\n",
    "            x=[-1*i for i in reversed(range(1,encoder_length+1))],\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(1, 21, 62, 1)\", width=2),\n",
    "            legendgroup=\"target\",\n",
    "            showlegend=False,\n",
    "            name=\"Target\"\n",
    "        ),\n",
    "\n",
    "        go.Scatter( # mean prediction\n",
    "            x=list(range(max_prediction_length)),\n",
    "            y=raw_predictions['prediction'][idx,:,3],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(117,187,253, 1)\", width=2),\n",
    "            name=\"Mean prediction\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    if j == 0: # set initial data to plot\n",
    "        fig_dict[\"data\"] = plot_data\n",
    "\n",
    "    frame = go.Frame(\n",
    "        data=plot_data,\n",
    "        name=str(idx),\n",
    "    )\n",
    "\n",
    "    fig_dict[\"frames\"].append(frame)\n",
    "\n",
    "    slider_step = {\"args\": [\n",
    "        [idx],\n",
    "        {\"frame\": {\"duration\": transition_duration, \"redraw\": False},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"transition\": {\"duration\": transition_duration},\n",
    "        }\n",
    "        ],\n",
    "        \"label\": idx,\n",
    "        \"method\": \"animate\"\n",
    "    }\n",
    "    sliders_dict[\"steps\"].append(slider_step)\n",
    "\n",
    "fig_dict[\"layout\"][\"sliders\"] = [sliders_dict]\n",
    "\n",
    "fig = go.Figure(fig_dict)\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        title=\"Electrical Load (kWh)\",\n",
    "        range=[0,kWh_max],\n",
    "        side=\"left\"\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"Prediction Loss\",\n",
    "        range=[0,2.5*np.mean(prediction_losses)],\n",
    "        anchor=\"x\",\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "        tickmode=\"sync\"\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        title=\"Attention\",\n",
    "        range=[0,max_attention],\n",
    "        anchor=\"free\",\n",
    "        overlaying=\"y\",\n",
    "        #side=\"left\",\n",
    "        showgrid=False,\n",
    "        autoshift=True\n",
    "    ),\n",
    "    legend=dict(\n",
    "        traceorder=\"reversed\",\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "ply_plot(\n",
    "    fig,\n",
    "    filename='temp.html',\n",
    "    auto_open=False,\n",
    "    auto_play=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try predicting on explicitly passed data as we will need to do for the forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slice = val_data.iloc[1242:1314]\n",
    "data_slice.iloc[-24:,data_slice.columns.get_loc('Equipment Electric Power [kWh]')] = 0\n",
    "explicit_dataset = TimeSeriesDataSet.from_dataset(training, data_slice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: because this model has known covariates over the prediction horizon, the explicit dataset we pass needs to have a length of `max_encoder_length`+`max_prediction_length`, but the target series values over the prediction horizons are (obviously) not used, so any values can be placed here (e.g. set to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_predictions = tft.predict(explicit_dataset, mode='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slice_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Annex37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
